{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor,StackingRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random_seed = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv(r'D:\\Envision Racing\\data\\train.csv')\n",
    "test_df = pd.read_csv(r'D:\\Envision Racing\\data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in to train and val set\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(train_df.drop(columns=[\"LAP_TIME\"]),\n",
    "                                               train_df[\"LAP_TIME\"],\n",
    "                                               test_size=0.03,\n",
    "                                               random_state=random_seed,\n",
    "                                               stratify=train_df['LOCATION'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# modify column names\n",
    "def mod_names(df):\n",
    "    df.columns = df.columns.str.lstrip() \n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "# drop unwanted features\n",
    "def drop_cols(df):\n",
    "    df.drop(columns = {\n",
    "        \"number\",\n",
    "        \"driver_number\",\n",
    "        \"lap_improvement\",\n",
    "        \"s1\",\n",
    "        \"s2\",\n",
    "        \"s3\",\n",
    "        \"s1_improvement\",\n",
    "        \"s2_improvement\",\n",
    "        \"s3_improvement\",\n",
    "        \"crossing_finish_line_in_pit\",\n",
    "        \"pit_time\",\n",
    "        \"group\",\n",
    "        \"team\",\n",
    "        \"power\",\n",
    "        \"kph\",\n",
    "        \"hour\",\n",
    "        \"elapsed\"\n",
    "    },inplace=True)\n",
    "\n",
    "# drop rows with missing values\n",
    "# nan_ft = ['s3_large','s1_large','s2_large']\n",
    "def drop_na_rows(df):\n",
    "    df.fillna(0, inplace=True)\n",
    "    # df.dropna(subset=nan_ft, axis=0, inplace=True)\n",
    "\n",
    "# convert hour feature to seconds\n",
    "def convert_time_to_seconds(x):\n",
    "    if type(x) is (int or float):\n",
    "        return x\n",
    "    else:\n",
    "        min = x.split(\":\")[0]\n",
    "        sec = x.split(\":\")[1]\n",
    "        sec = float(sec)\n",
    "        min = float(min)\n",
    "        sec = sec/60\n",
    "        return min + sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanse data\n",
    "def cleanse(df):\n",
    "    mod_names(df)\n",
    "    drop_cols(df)\n",
    "    drop_na_rows(df)\n",
    "    df[\"s3_large\"] = df[\"s3_large\"].apply(convert_time_to_seconds)\n",
    "    df[\"s2_large\"] = df[\"s2_large\"].apply(convert_time_to_seconds)\n",
    "    df[\"s1_large\"] = df[\"s1_large\"].apply(convert_time_to_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanse(X_train)\n",
    "cleanse(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9967, 7) (309, 7) (9967,) (309,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_val.shape,Y_train.shape,Y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fts = [\"driver_name\",\"location\",\"event\"]\n",
    "num_fts = [\"lap_number\",\"s1_large\",\"s2_large\",\"s3_large\"]\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "ct = make_column_transformer(\n",
    "                        (std_scaler, num_fts),\n",
    "                        (ohe, cat_fts),\n",
    "                        remainder='passthrough',\n",
    "                        n_jobs=-1,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvr_params = {'C': 1, 'dual': True, 'epsilon': 0.1, 'loss': 'epsilon_insensitive', 'tol': 0.001}\n",
    "linear_svr = LinearSVR(\n",
    "    C=lsvr_params['C'],\n",
    "    epsilon=lsvr_params['epsilon'],\n",
    "    tol=lsvr_params['tol'],\n",
    "    loss=lsvr_params['loss'],\n",
    "    dual=lsvr_params['dual'],\n",
    "    verbose=1,\n",
    "    max_iter=100000,\n",
    "    random_state=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=200,criterion=\"mae\",\n",
    "                            max_depth=5,\n",
    "                            n_jobs=-1,random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lsvr',linear_svr),\n",
    "    ('rf',rf)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,max_depth=3,random_state=random_seed),\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# final estimator is trained only on preds of lsvr and rf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_pipeline = make_pipeline(ct,stk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=-1, remainder='passthrough',\n",
       "                                   transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['lap_number', 's1_large',\n",
       "                                                   's2_large', 's3_large']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['driver_name', 'location',\n",
       "                                                   'event'])],\n",
       "                                   verbose=True)),\n",
       "                ('stackingregressor',\n",
       "                 StackingRegressor(estimators=[('lsvr',\n",
       "                                                LinearSVR(C=1, epsilon=0.1,\n",
       "                                                          max_iter=100000,\n",
       "                                                          random_state=100,\n",
       "                                                          tol=0.001,\n",
       "                                                          verbose=1)),\n",
       "                                               ('rf',\n",
       "                                                RandomForestRegressor(criterion='mae',\n",
       "                                                                      max_depth=5,\n",
       "                                                                      n_estimators=200,\n",
       "                                                                      n_jobs=-1,\n",
       "                                                                      random_state=100))],\n",
       "                                   final_estimator=RandomForestRegressor(max_depth=3,\n",
       "                                                                         n_estimators=10,\n",
       "                                                                         random_state=100),\n",
       "                                   n_jobs=-1))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk_pipeline.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_lsvr_pipeline.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump trained model\n",
    "dump(stk_pipeline,'rf_lsvr_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score:  0.4903479528510646\n"
     ]
    }
   ],
   "source": [
    "#  validate\n",
    "y_pred = stk_pipeline.predict(X_val)\n",
    "\n",
    "print(\"validation score: \",np.sqrt(metrics.mean_squared_log_error(Y_val,y_pred)))\n",
    "# print(\"stk regressor train fit score\",stk_pipeline.score(X_train,X_val))\n",
    "# print(\"Validation_fit score: \",(stk_pipeline.score(X_val,Y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanse(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LAP_TIME\n",
      "0  96.172533\n",
      "1  96.172533\n",
      "2  96.683025\n",
      "3  97.280423\n",
      "4  97.280423\n",
      "         LAP_TIME\n",
      "count  420.000000\n",
      "mean    90.541840\n",
      "std     10.287115\n",
      "min     60.966906\n",
      "25%     76.099256\n",
      "50%     96.172533\n",
      "75%     97.280423\n",
      "max    100.340029\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "preds = stk_pipeline.predict(test_df.drop(columns=[\"lap_time\"]))\n",
    "\n",
    "submission = pd.read_csv(r'D:\\Envision Racing\\data\\submission.csv')\n",
    "submission['LAP_TIME'] = preds\n",
    "submission.to_csv('rf_lsvr_ensemble_preds.csv', index=False)\n",
    "\n",
    "print(submission.head())\n",
    "print(submission.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "518a807dccee1bb2cf00c0cea9388abbe4210a3c385c01718c979ef7759eaf87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
